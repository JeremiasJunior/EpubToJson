{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebooklib import epub\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Epub:\n",
    "    \n",
    "    def __init__(self, file_path):\n",
    "        self.book = epub.read_epub(file_path)\n",
    "        self.version = self.detect_epub_version()\n",
    "\n",
    "    def detect_epub_version(self):\n",
    "        if 'toc.ncx' in [item.file_name for item in self.book.get_items()]:\n",
    "            return '2.0'\n",
    "        elif 'nav.xhtml' in [item.file_name for item in self.book.get_items()]:\n",
    "            return '3.0'\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported EPUB format\")\n",
    "        \n",
    "    def get_nav_points(self):\n",
    "        if self.version == '2.0':\n",
    "            toc_file = self.book.get_item_with_id('toc.ncx')\n",
    "            return self.parse_toc_ncx(toc_file)\n",
    "        elif self.version == '3.0':\n",
    "            nav_file = self.book.get_item_with_id('nav.xhtml')\n",
    "            return self.parse_nav_xhtml(nav_file)\n",
    "\n",
    "    def parse_toc_ncx(self, toc_file):\n",
    "        soup = BeautifulSoup(toc_file.content, 'lxml')\n",
    "        nav_points = soup.find_all('navpoint')\n",
    "        chapters = []\n",
    "        for point in nav_points:\n",
    "            title = point.navlabel.text\n",
    "            src = point.content['src']\n",
    "            chapters.append((title, src))\n",
    "        return chapters\n",
    "\n",
    "    def parse_nav_xhtml(self, nav_file):\n",
    "        soup = BeautifulSoup(nav_file.content, 'lxml')\n",
    "        nav_points = soup.select('nav ol li a')\n",
    "        chapters = []\n",
    "        for point in nav_points:\n",
    "            title = point.text\n",
    "            src = point['href']\n",
    "            chapters.append((title, src))\n",
    "        return chapters\n",
    "    \n",
    "    def extract_chapter_content(self, src):\n",
    "        content_item = self.book.get_item_with_href(src)\n",
    "        soup = BeautifulSoup(content_item.content, 'lxml')\n",
    "        return soup.get_text(separator='\\n', strip=True)\n",
    "\n",
    "    def get_chapters(self):\n",
    "        chapters = self.get_nav_points()\n",
    "        chapter_data = {}\n",
    "        for title, src in chapters:\n",
    "            chapter_content = self.extract_chapter_content(src)\n",
    "            chapter_data[title] = chapter_content\n",
    "        return chapter_data\n",
    "    \n",
    "    def extract_chapter_content(self, src):\n",
    "        try:\n",
    "            content_item = self.book.get_item_with_href(src)\n",
    "            if content_item:\n",
    "                soup = BeautifulSoup(content_item.content, 'lxml')\n",
    "                return soup.get_text(separator='\\n', strip=True)\n",
    "            else:\n",
    "                return \"Content not found\"\n",
    "        except Exception as e:\n",
    "            return f\"Error extracting content: {e}\"\n",
    "    \n",
    "    def write_to_json(self, output_path):\n",
    "        chapters = self.get_chapters()\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(chapters, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
